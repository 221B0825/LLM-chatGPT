{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.59.8)\n",
      "Collecting openai\n",
      "  Downloading openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m472.3/472.3 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.9/54.9 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.5)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35\n",
      "  Downloading langchain_core-0.3.35-py3-none-any.whl (413 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m413.2/413.2 KB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-text-splitters<1.0.0,>=0.3.6\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Collecting numpy<2,>=1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17\n",
      "  Downloading langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m332.8/332.8 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken<1,>=0.7\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m205.1/205.1 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Collecting zstandard<0.24.0,>=0.23.0\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m599.5/599.5 KB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (2.0)\n",
      "Installing collected packages: zstandard, tenacity, regex, propcache, numpy, multidict, jsonpatch, greenlet, frozenlist, async-timeout, aiohappyeyeballs, yarl, tiktoken, SQLAlchemy, requests-toolbelt, aiosignal, openai, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Not uninstalling jsonpatch at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "    Can't uninstall 'jsonpatch'. No files were found to uninstall.\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.59.8\n",
      "    Uninstalling openai-1.59.8:\n",
      "      Successfully uninstalled openai-1.59.8\n",
      "Successfully installed SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 async-timeout-4.0.3 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.19 langchain-core-0.3.35 langchain-openai-0.3.6 langchain-text-splitters-0.3.6 langsmith-0.3.8 multidict-6.1.0 numpy-1.26.4 openai-1.63.2 propcache-0.2.1 regex-2024.11.6 requests-toolbelt-1.0.0 tenacity-9.0.0 tiktoken-0.9.0 yarl-1.18.3 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain-core==0.2.17\n",
    "#!pip install langchain-openai==0.1.17\n",
    "#!pip install pydantic==1.10.8\n",
    "#!pip install pydantic_core==2.18.2\n",
    "%pip install -U openai langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field # ì˜ˆì „ ë°©ì‹\n",
    "\n",
    "# from pydantic import BaseModel # ìƒˆë¡œìš´ ë°©ì‹\n",
    "\n",
    "from pydantic.v1 import BaseModel # pydantic.v1 í˜¸í™˜ì´ í•„ìš”í•œ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17145/3759826758.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(model=\"gpt-4o-mini\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ ì¢‹ì€ ê¸°ë¶„ì„ ìœ ì§€í• ê¹Œìš”?\\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ìŠ¤ì¿±\"ì´ ìˆê¸° ë•Œë¬¸ì´ì£ ! ğŸ¦ğŸ˜„'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}ì— ëŒ€í•œ ê°„ë‹¨í•œ ë†ë‹´ì„ ë§í•´ì¤˜.\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser # LCELì˜ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "chain.invoke({\"topic\": \"ì•„ì´ìŠ¤í¬ë¦¼\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docarray\n",
      "  Downloading docarray-0.40.0-py3-none-any.whl (270 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m270.2/270.2 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from docarray) (2.10.5)\n",
      "Collecting typing-inspect>=0.8.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (13.9.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.26.4)\n",
      "Collecting types-requests>=2.28.11.6\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray) (3.10.15)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (2.19.1)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
      "Installing collected packages: urllib3, mypy-extensions, typing-inspect, types-requests, docarray\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.5\n",
      "    Not uninstalling urllib3 at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
      "Successfully installed docarray-0.40.0 mypy-extensions-1.0.0 types-requests-2.32.0.20241016 typing-inspect-0.9.0 urllib3-2.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install docarray tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17145/755495277.py:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding=OpenAIEmbeddings(),\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain docarray tiktoken\n",
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"í•´ë¦¬ìŠ¨ì€ í•™êµì—ì„œ ì¼í•©ë‹ˆë‹¤.\", \"ê³°ì€ ê¿€ì„ ì¢‹ì•„í•´\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"ë‹¤ìŒ ì§€ë¬¸ì—ë§Œ ê·¼ê±°í•´ì„œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel( # ì—¬ëŸ¬ê°œì˜ Runnableì„ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} # RunnablePassthroughëŠ” ê°’ì„ ì…ë ¥ë°›ì•„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ê°ì²´\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "# retrieval | prompt | model | output. RAGì˜ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹µë³€: í•™êµì—ì„œ ì¼í•©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"í•´ë¦¬ìŠ¨ì€ ì–´ë””ì—ì„œ ì¼í•˜ë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹µë³€: ê³°ì€ ê¿€ì„ ì¢‹ì•„í•©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.invoke(\"ê³°ì€ ë¬´ì—‡ì„ ì¢‹ì•„í•˜ë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ ì¢‹ì€ ê¸°ë¶„ì„ ê°€ì§€ê³  ìˆì„ê¹Œìš”? \n",
      "\n",
      "ì™œëƒí•˜ë©´ ì–¸ì œë‚˜ \"ìŠ¤ì¿±\"ì´ ìˆê¸° ë•Œë¬¸ì´ì£ ! ğŸ¦ğŸ˜„"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}ì— ëŒ€í•œ ê°„ë‹¨í•œ ë†ë‹´ì„ í•´ì¤˜.\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "for chunk in chain.stream(\"ice cream\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì•„ì´ìŠ¤í¬ë¦¼ì´ ì™œ í•­ìƒ í–‰ë³µí• ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ìŠ¤ì¿±\"ì´ ë§ìœ¼ë‹ˆê¹Œìš”! ğŸ¦ğŸ˜„',\n",
       " 'ì™œ ìŠ¤íŒŒê²Œí‹°ëŠ” í•™êµì—ì„œ í•­ìƒ ì¢‹ì€ ì„±ì ì„ ë°›ì„ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ì•Œ ë´ë–¼\" ìƒíƒœë‹ˆê¹Œìš”! ğŸğŸ˜',\n",
       " 'ë§Œë‘ê°€ ì¹œêµ¬ì—ê²Œ ë§í–ˆì–´ìš”. \"ë„ˆ ì™œ ì´ë ‡ê²Œ ìª¼ê·¸ë ¤ ì•‰ì•„ ìˆì–´?\" ì¹œêµ¬ê°€ ë‹µí–ˆì–´ìš”. \"ë„ˆë¬´ ë§Œë‘ê°€ ë¨¹ê³  ì‹¶ì–´ì„œ!\"']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([\"ì•„ì´ìŠ¤í¬ë¦¼\", \"ìŠ¤íŒŒê²Œí‹°\", \"ë§Œë‘\"])\n",
    "\n",
    "# stream: ì…ë ¥ì— ëŒ€í•´ ì²­í¬ë¥¼ ìŠ¤íŠ¸ë¦¬ë°\n",
    "# invoke: ì…ë ¥ì— ëŒ€í•´ ì²´ì¸ì„ í˜¸ì¶œ\n",
    "# batch: ì…ë ¥ëª©ë¡ì— ëŒ€í•´ ì²´ì¸ì„ ë°°ì¹˜ë¡œ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ ê¸°ë¶„ì´ ì¢‹ì„ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ ì–¸ì œë‚˜ \"ìŠ¤ì¿±\"í•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆìœ¼ë‹ˆê¹Œìš”! ğŸ¦ğŸ˜„'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke(\"ice cream\")\n",
    "\n",
    "# astream: ë¹„ë™ê¸°ë¡œ ì…ë ¥ì— ëŒ€í•´ ì²­í¬ë¥¼ ìŠ¤íŠ¸ë¦¬ë°\n",
    "# ainvoke: ë¹„ë™ê¸°ë¡œ ì…ë ¥ì— ëŒ€í•´ ì²´ì¸ì„ í˜¸ì¶œ\n",
    "# abatch: ë¹„ë™ê¸°ë¡œ ì…ë ¥ëª©ë¡ì— ëŒ€í•´ ì²´ì¸ì„ ë°°ì¹˜ë¡œ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ í–‰ë³µí• ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ìŠ¤ì¿±\"ì„ ë°›ì•„ì„œìš”! ğŸ¦ğŸ˜„',\n",
       " 'ì™œ ìŠ¤íŒŒê²Œí‹°ëŠ” í•­ìƒ íŒŒí‹°ì— ì´ˆëŒ€ë°›ëŠ” ê±¸ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´, í•­ìƒ \"ì†ŒìŠ¤\"ê°€ ì¢‹ê±°ë“ ìš”! ğŸğŸ˜„',\n",
       " 'ì™œ ë§Œë‘ê°€ í•­ìƒ í–‰ë³µí• ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ ì†ì´ ê½‰ ì°¨ìˆì–´ì„œìš”! ğŸ˜„']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch(\n",
    "    [\"ì•„ì´ìŠ¤í¬ë¦¼\", \"ìŠ¤íŒŒê²Œí‹°\", \"ë§Œë‘\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'root': {'title': 'Root'}},\n",
       " 'required': ['root'],\n",
       " 'title': 'RunnableParallel<topic>Input',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'StrOutputParserOutput', 'type': 'string'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.model_json_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
